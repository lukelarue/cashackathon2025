{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538d7788-f7f2-458d-937e-74b3f3002bbc",
   "metadata": {},
   "source": [
    "# 1) Attendance Plots & Segmentation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d0184-8541-40f1-933f-f0c1f940c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33be24-f169-4b5d-ae0e-745ed3b12555",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_df = pl.read_csv('primary_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3993ac-9ab7-4de8-98c6-1c8edacabc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_df = pl.read_csv('secondary_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46771393-042d-42e6-99d8-237cfd2a8aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df = pl.read_csv('primary_data_reference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a64285-fb34-4161-a8ad-36d038a422d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_df = primary_df.with_columns(\n",
    "    (pl.col(\"associate_date\").is_not_null()).alias(\"ACAS\"),\n",
    "    (pl.col(\"Fellow_Date\").is_not_null()).alias(\"FCAS\")\n",
    ")\n",
    "primary_df = primary_df.with_columns(\n",
    "    pl.when(pl.col(\"FCAS\"))\n",
    "      .then(pl.lit(\"FCAS\"))\n",
    "      .when(pl.col(\"ACAS\"))\n",
    "      .then(pl.lit(\"ACAS\"))\n",
    "      .otherwise(pl.lit(\"non-member\"))\n",
    "      .alias(\"membership_type\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed4a48-1983-4bf8-a8c3-450b34b52c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_pie_IP = primary_df.filter(pl.col('Delivery')=='IP').to_pandas()\n",
    "pdf_pie_LS = primary_df.filter(pl.col('Delivery')=='LS').to_pandas()\n",
    "pdf_pie_V = primary_df.filter(pl.col('Delivery')=='V').to_pandas()\n",
    "pdf_pie_all = primary_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d2da6-f617-4bab-88cb-2953fc4e52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pies(df, group_col, event_col=\"Event_Code\"):\n",
    "    event_codes = df[event_col].unique()\n",
    "    n = len(event_codes)\n",
    "\n",
    "    fig, axes = plt.subplots(1, n, figsize=(4*n, 4))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, event in zip(axes, event_codes):\n",
    "        subset = df[df[event_col] == event]\n",
    "        counts = subset[group_col].value_counts()\n",
    "\n",
    "        ax.pie(counts, labels=counts.index, autopct=\"%1.1f%%\")\n",
    "        ax.set_title(f\"{event} - {group_col}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbffbbe-b895-4c6c-bbb1-ed3aa8942eec",
   "metadata": {},
   "source": [
    "IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de9a2d-8d24-431e-8116-59a7efc28ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pies(pdf_pie_IP, \"registrant_type_code\")\n",
    "plot_pies(pdf_pie_IP, \"membership_type\")\n",
    "plot_pies(pdf_pie_IP, \"State\")\n",
    "plot_pies(pdf_pie_IP, \"Country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7d2eb3-a26a-4717-8a28-4569f9d9b92c",
   "metadata": {},
   "source": [
    "LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258ef0a-34a6-4123-87fc-a1ad6d2baca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pies(pdf_pie_LS, \"registrant_type_code\")\n",
    "plot_pies(pdf_pie_LS, \"membership_type\")\n",
    "plot_pies(pdf_pie_LS, \"State\")\n",
    "plot_pies(pdf_pie_LS, \"Country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c642213d-1b61-4b2a-920e-a12a42910d73",
   "metadata": {},
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedee72a-aea5-490f-92da-e8b3a97e8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pies(pdf_pie_V, \"registrant_type_code\")\n",
    "plot_pies(pdf_pie_V, \"membership_type\")\n",
    "plot_pies(pdf_pie_V, \"State\")\n",
    "plot_pies(pdf_pie_V, \"Country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977e8e9-063a-40c0-876a-6ce15c29e917",
   "metadata": {},
   "source": [
    "all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da40ad-edf8-43cf-88c7-48416521b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pies(pdf_pie_all, \"registrant_type_code\")\n",
    "plot_pies(pdf_pie_all, \"membership_type\")\n",
    "plot_pies(pdf_pie_all, \"State\")\n",
    "plot_pies(pdf_pie_all, \"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8578444c-58aa-4f03-9c8c-d1be6a5a9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_df_parent_events = [\n",
    "    \"2015RPM\", \"15Spring\", \"2015REINS\", \"15CLRS\", \"15CLRS\", \"15Annual\", \"2016RPM\", \"16Spring\", \"16Spring\", \"2016REINS\",\n",
    "    \"16CLRS\", \"16CLRS\", \"16Annual\", \"17RPM\", \"17Spring\", \"17Spring\", \"2017REINS\", \"17CLRS\", \"17CLRS\", \"17Annual\",\n",
    "    \"17Annual\", \"18RPM\", \"18Spring\", \"18Spring\", \"2018REINS\", \"18CLRS\", \"18CLRS\", \"18Annual\", \"18Annual\", \"19RPM\",\n",
    "    \"19RPM\", \"19Spring\", \"19Spring\", \"2019REINS\", \"2019REINS\", \"19CLRS\", \"19CLRS\", \"19Annual\", \"19Annual\", \"20VirSprng\",\n",
    "    \"20VREINS\", \"20VRPM\", \"20VRCLRS\", \"20VirAnn\", \"21VRPM\", \"21VirSprng\", \"21VREINS\", \"21VRCLRS\", \"21Annual\", \"21Annual\",\n",
    "    \"RPMLive22\", \"22Spring\", \"22Spring\", \"22VREINS\", \"22CLRS\", \"22CLRS\", \"22Annual\", \"22Annual\", \"23RPM\", \"23RPM\",\n",
    "    \"23Spring\", \"23Spring\", \"23REI\", \"23REI\", \"23CLRS\", \"23CLRS\", \"23Annual\", \"23Annual\", \"24RPM\", \"24RPM\",\n",
    "    \"24Spring\", \"24Spring\", \"24Reins\", \"24Reins\", \"24CLRS\", \"24CLRS\", \"24Annual\", \"24Annual\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f818b8f-7047-4fcd-beb5-b9be192f5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_event_type_column(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.with_columns(\n",
    "    pl.when(pl.col(\"parent_event\").str.to_lowercase().str.contains(\"ann\"))\n",
    "      .then(pl.lit(\"Annual\"))\n",
    "    .when(pl.col(\"parent_event\").str.to_lowercase().str.contains(\"clrs\"))\n",
    "      .then(pl.lit(\"CLRS\"))\n",
    "    .when(pl.col(\"parent_event\").str.to_lowercase().str.contains(\"rpm\"))\n",
    "      .then(pl.lit(\"RPM\"))\n",
    "    .when(pl.col(\"parent_event\").str.to_lowercase().str.contains(\"rei\"))\n",
    "      .then(pl.lit(\"REINS\"))\n",
    "    .when(pl.col(\"parent_event\").str.to_lowercase().str.contains(\"spr\"))\n",
    "      .then(pl.lit(\"Spring\"))\n",
    "    .otherwise(pl.lit(\"type not found\"))\n",
    "    .alias(\"event_type\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1c543-f277-4858-b25f-71fa291d1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_df_grouped = (\n",
    "    primary_df.group_by(\"Event_Title\")\n",
    "      .agg([\n",
    "          pl.col(\"Event_Code\").first().alias(\"Event_Code\"),\n",
    "\n",
    "          pl.col(\"Start_Date\").first().alias(\"Start_Date\"),\n",
    "\n",
    "          pl.col(\"Delivery\").first().alias(\"Delivery\"),\n",
    "\n",
    "          pl.col(\"Location_City\").first().alias(\"Location_City\"),\n",
    "\n",
    "          pl.col(\"Location_State\").first().alias(\"Location_State\"),\n",
    "\n",
    "          pl.len().alias(\"attendance\"),\n",
    "      ])\n",
    ").with_columns(\n",
    "        pl.col(\"Start_Date\")\n",
    "        .str.strptime(pl.Date, \"%m/%d/%Y\", strict=False)\n",
    "        .alias(\"Start_Date\")\n",
    ").sort(by='Start_Date').with_columns(\n",
    "   pl.Series(\"parent_event\", primary_df_parent_events)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025ab69-4193-4c96-be43-49f60b8fa48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_df_grouped = add_event_type_column(primary_df_grouped)\n",
    "primary_df_grouped = primary_df_grouped.with_columns(pl.concat_str([pl.col(\"Location_City\"), pl.lit(\", \"), pl.col(\"Location_State\")]).alias(\"city_state\"))\n",
    "\n",
    "totals_ip_ls = (\n",
    "    primary_df_grouped\n",
    "    .filter(pl.col(\"Delivery\").is_in([\"IP\", \"LS\"]))\n",
    "    .group_by(\"parent_event\")\n",
    "    .agg([\n",
    "        pl.col(\"attendance\").sum().alias(\"attendance\"),\n",
    "        pl.lit(\"IP+LS\").alias(\"Delivery\"),\n",
    "\n",
    "        pl.col(\"Location_City\").first().alias(\"Location_City\"),\n",
    "        pl.col(\"Location_State\").first().alias(\"Location_State\"),\n",
    "        pl.col(\"city_state\").first().alias(\"city_state\"),\n",
    "        pl.col(\"event_type\").first().alias(\"event_type\"),\n",
    "        pl.col(\"Start_Date\").first().alias(\"Start_Date\"),\n",
    "\n",
    "        pl.lit(None, dtype=pl.Utf8).alias(\"Event_Title\"),\n",
    "        pl.lit(None, dtype=pl.Utf8).alias(\"Event_Code\"),\n",
    "    ])\n",
    ")\n",
    "primary_df_grouped_combined = pl.concat([primary_df_grouped, totals_ip_ls], how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc3f417-edff-461c-bb05-baeac51edba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_line_CLRS = primary_df_grouped_combined.filter(pl.col('event_type')=='CLRS').to_pandas()\n",
    "pdf_line_Annual = primary_df_grouped_combined.filter(pl.col('event_type')=='Annual').to_pandas()\n",
    "pdf_line_RPM = primary_df_grouped_combined.filter(pl.col('event_type')=='RPM').to_pandas()\n",
    "pdf_line_REINS = primary_df_grouped_combined.filter(pl.col('event_type')=='REINS').to_pandas()\n",
    "pdf_line_Spring = primary_df_grouped_combined.filter(pl.col('event_type')=='Spring').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2d3c0-34f0-4958-bc2a-1f17e6249caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_by_delivery(df, event_type):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    ax = sns.lineplot(\n",
    "        data=df,\n",
    "        x=\"Start_Date\",\n",
    "        y=\"attendance\",\n",
    "        marker=\"o\",\n",
    "        hue=\"Delivery\"\n",
    "    )\n",
    "    for (x, y, txt) in zip(df[\"Start_Date\"], df[\"attendance\"], df['city_state']):\n",
    "        ax.annotate(\n",
    "            txt,\n",
    "            xy=(x, y),\n",
    "            xytext=(0, 6),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8\n",
    "        )\n",
    "    \n",
    "    plt.title(f\"{event_type} Event Attendance Over Time\", fontsize=16)\n",
    "    plt.xlabel(\"Event Date\")\n",
    "    plt.ylabel(\"Attendance\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00f396-6058-46da-8ceb-a685c4061bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_by_delivery(pdf_line_CLRS, \"CLRS\")\n",
    "plot_line_by_delivery(pdf_line_Annual, \"Annual\")\n",
    "plot_line_by_delivery(pdf_line_RPM, \"RPM\")\n",
    "plot_line_by_delivery(pdf_line_REINS, \"REINS\")\n",
    "plot_line_by_delivery(pdf_line_Spring, \"Spring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc620f6-4871-444f-bb65-f58770ae6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_order = [\"Annual\", \"CLRS\", \"REINS\", \"RPM\", \"Spring\"]\n",
    "\n",
    "colors = sns.color_palette(\"tab10\", n_colors=len(event_type_order))\n",
    "EVENT_TYPE_TO_COLOR = dict(zip(event_type_order, colors))\n",
    "\n",
    "pdf_line_IP = primary_df_grouped_combined.filter(pl.col('Delivery')=='IP').to_pandas()\n",
    "pdf_line_LS = primary_df_grouped_combined.filter(pl.col('Delivery')=='LS').to_pandas()\n",
    "pdf_line_IPLS = primary_df_grouped_combined.filter(pl.col('Delivery')=='IP+LS').to_pandas()\n",
    "\n",
    "for df in (pdf_line_IP, pdf_line_LS, pdf_line_IPLS):\n",
    "    df[\"event_type\"] = pd.Categorical(df[\"event_type\"], categories=event_type_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7489f84b-dbdf-4d7d-b0a9-0b3e8a01c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import date\n",
    "\n",
    "df = pl.from_pandas(pdf_line_IPLS)\n",
    "Y_COL = \"attendance\"\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.col(\"Start_Date\").dt.year().alias(\"year\"),\n",
    "        pl.col(Y_COL).cast(pl.Float64)\n",
    "    )\n",
    ")\n",
    "\n",
    "target_years = np.array([2026, 2027], dtype=np.int32)\n",
    "target_dates = [date(2026, 1, 1), date(2027, 1, 1)]\n",
    "\n",
    "event_types = df.select(pl.col(\"event_type\").unique()).to_series().to_list()\n",
    "pred_rows = []\n",
    "\n",
    "for et in event_types:\n",
    "    sub = df.filter(pl.col(\"event_type\") == et).drop_nulls(subset=[\"year\", Y_COL])\n",
    "\n",
    "    X = sub.select(\"year\").to_numpy()\n",
    "    y = sub.select(Y_COL).to_numpy().ravel()\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "\n",
    "    y_pred = lr.predict(target_years.reshape(-1, 1))\n",
    "    y_pred_int = np.clip(np.round(y_pred).astype(int), 0, None)\n",
    "\n",
    "    for i, yr in enumerate(target_years):\n",
    "        pred_rows.append({\n",
    "            \"event_type\": et,\n",
    "            \"Start_Date\": target_dates[i],\n",
    "            \"year\": int(yr),\n",
    "            Y_COL: int(y_pred_int[i]),\n",
    "            \"Event_Title\": None,\n",
    "            \"Event_Code\": None,\n",
    "            \"Location_City\": \"\",\n",
    "            \"Location_State\": \"\",\n",
    "            \"city_state\": \"\",\n",
    "            \"Delivery\": \"IP+LS\",\n",
    "            \"parent_event\": \"\"\n",
    "        })\n",
    "\n",
    "preds_df = pl.from_records(pred_rows)\n",
    "cols = df.columns\n",
    "display(preds_df.filter(pl.col('Location_City')==\"\").sort(by='event_type').select(['event_type', 'year', 'attendance']))\n",
    "pdf_line_IPLS = pl.concat([df, preds_df[cols]], how=\"vertical_relaxed\").sort([\"event_type\", \"year\"]).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8274f-0427-470b-9743-077d28f11606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_by_event_type(df, event_type, projected=False):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    ax = sns.lineplot(\n",
    "        data=df,\n",
    "        x=\"Start_Date\",\n",
    "        y=\"attendance\",\n",
    "        marker=\"o\",\n",
    "        hue=\"event_type\",\n",
    "        hue_order=event_type_order,\n",
    "        palette=EVENT_TYPE_TO_COLOR\n",
    "    )\n",
    "    for (x, y, txt) in zip(df[\"Start_Date\"], df[\"attendance\"], df['city_state']):\n",
    "        ax.annotate(\n",
    "            txt,\n",
    "            xy=(x, y),\n",
    "            xytext=(0, 6),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8\n",
    "        )\n",
    "    if projected:\n",
    "        plt.title(f\"{event_type} Event Attendance Over Time (2026 and 2027 points projected)\", fontsize=16)\n",
    "    else:\n",
    "        plt.title(f\"{event_type} Event Attendance Over Time\", fontsize=16)\n",
    "    plt.xlabel(\"Event Date\")\n",
    "    plt.ylabel(\"Attendance\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af653f59-1106-422f-baf5-4dd92e5f6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_by_event_type(pdf_line_IP, \"IP\")\n",
    "plot_line_by_event_type(pdf_line_LS, \"LS\")\n",
    "plot_line_by_event_type(pdf_line_IPLS, \"IP+LS\", projected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd1a35-d056-42f6-b1aa-ee4d580ed50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_event_types = [\n",
    "    'CLRS', 'CLRS', 'ANN', 'ANN', 'RPM', 'RPM', 'SPR', 'SPR', 'SPR', 'REI', 'REI', 'CLRS',\n",
    "    'CLRS', 'CLRS', 'CSAF', 'ANN', 'ANN', 'ANN', 'ANN', 'RPM', 'RPM', 'SPR', 'SPR', 'REI',\n",
    "    'REI', 'CLRS', 'CLRS', 'ANN', 'ANN', 'ANN', 'RPM', 'RPM', 'SPR', 'SPR', 'REI', 'REI',\n",
    "    'CLRS', 'CLRS', 'ANN', 'ANN', 'ANN', 'RPM', 'RPM', 'RPM', 'SPR', 'SPR', 'REI', 'REI',\n",
    "    'CLRS', 'CLRS', 'ANN', 'ANN', 'RPM', 'RPM', 'RPM', 'RPM', 'SPR', 'SPR', 'SPR', 'REI',\n",
    "    'REI', 'CARE', 'CLRS', 'CLRS', 'ANN', 'ANN', 'ANN', 'RPM', 'SPR', 'SPR', 'SPR', 'REI',\n",
    "    'REI', 'REI', 'REI', 'RPM', 'CLRS', 'CLRS', 'CLRS', 'CLRS', 'CSAF', 'ANN', 'ANN', 'RPM',\n",
    "    'RPM', 'RPM', 'RPM', 'SPR', 'SPR', 'SPR', 'REI', 'REI', 'REI', 'REI', 'CLRS', 'CLRS',\n",
    "    'CLRS', 'CLRS', 'ANN', 'ANN', 'RPM', 'RPM', 'RPM', 'RPM', 'SPR', 'SPR', 'REI', 'REI',\n",
    "    'CLRS', 'CLRS', 'CLRS', 'CLRS', 'ANN', 'RPM', 'RPM', 'RPM', 'SPR', 'REI', 'REI', 'REI',\n",
    "    'CLRS', 'CLRS', 'CLRS', 'ANN', 'RPM', 'RPM', 'SPR', 'REI', 'REI', 'REI', 'CLRS', 'CLRS',\n",
    "    'CLRS', 'ANN', 'RPM', 'RPM', 'RPM', 'SPR', 'REI', 'REI', 'REI'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92142a6a-7b41-4641-b08e-17b948a5807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_df_grouped = secondary_df.group_by('Meeting').agg([pl.col('Begin_Date').first(), pl.len().alias('attendance')]).with_columns(\n",
    "        pl.col(\"Begin_Date\")\n",
    "        .str.strptime(pl.Date, \"%m/%d/%Y\", strict=False)\n",
    "        .alias(\"Begin_Date\")\n",
    ").sort(by='Begin_Date').with_columns(\n",
    "   pl.Series(\"event_type\", secondary_event_types),\n",
    "    pl.col(\"Meeting\").str.slice(0, 4).alias(\"Year\")\n",
    "    ).with_columns(pl.concat_str(\n",
    "        [pl.col(\"Year\"), pl.col(\"event_type\")],\n",
    "        separator=\"\"\n",
    "    ).alias(\"year_and_event\"))\n",
    "\n",
    "secondary_event_totals = secondary_df_grouped.group_by('year_and_event').agg([pl.col('attendance').sum(), pl.col('Begin_Date').first(), pl.col('event_type').first()]).sort(by='Begin_Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54e677-3a31-4702-a118-77e88fe5cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "pdf = secondary_event_totals.filter(pl.col('year_and_event')!='2014ANN').to_pandas()  \n",
    "# Remove 2014 Annual as it was the CAS Centenniel Celebration and was an outlier, distorting the chart.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(\n",
    "    data=pdf,\n",
    "    x=\"Begin_Date\",\n",
    "    y=\"attendance\",\n",
    "    hue=\"event_type\",\n",
    "    marker=\"o\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Attendance over time by event type (Secondary Data Validation)\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Attendance\")\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax.legend(title=\"Event type\", frameon=False, bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ccd6b0-127e-43ce-b9ab-c997b3c3314a",
   "metadata": {},
   "source": [
    "# 2) Add Location and Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90ad02-c68a-460c-8025-98dc6bd50c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "CACHE_PATH = Path(\"geocode_cache.json\")\n",
    "\n",
    "def load_cache() -> dict:\n",
    "    if CACHE_PATH.exists():\n",
    "        return json.loads(CACHE_PATH.read_text(encoding=\"utf-8\"))\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache: dict) -> None:\n",
    "    tmp = CACHE_PATH.with_suffix(\".tmp\")\n",
    "    tmp.write_text(json.dumps(cache, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    tmp.replace(CACHE_PATH)\n",
    "\n",
    "\n",
    "def build_unique_place_keys(primary_df) -> list[str]:\n",
    "    people_keys = primary_df.select(\n",
    "        pl.concat_str(\n",
    "            [pl.col(\"City\"), pl.col(\"State\"), pl.col(\"Country\")],\n",
    "            separator=\", \",\n",
    "            ignore_nulls=True,\n",
    "        ).alias(\"place_key\")\n",
    "    )\n",
    "    meeting_keys = primary_df.select(\n",
    "        pl.concat_str(\n",
    "            [pl.col(\"Location_City\"), pl.col(\"Location_State\")],\n",
    "            separator=\", \",\n",
    "            ignore_nulls=True,\n",
    "        ).alias(\"place_key\")\n",
    "    )\n",
    "    out = (\n",
    "        pl.concat([people_keys, meeting_keys])\n",
    "        .unique()\n",
    "        .filter(pl.col(\"place_key\").str.len_chars() > 0)\n",
    "        .get_column(\"place_key\")\n",
    "        .to_list()\n",
    "    )\n",
    "    return out\n",
    "\n",
    "def geocode_all(unique_place_keys: Iterable[str], save_every: int = 50) -> None:\n",
    "    cache = load_cache()\n",
    "\n",
    "    geolocator = Nominatim(user_agent=\"meetings-distance\")\n",
    "    geocode = RateLimiter(\n",
    "        geolocator.geocode,\n",
    "        min_delay_seconds=1,         \n",
    "        max_retries=2,               \n",
    "        error_wait_seconds=5,\n",
    "        swallow_exceptions=True,     \n",
    "    )\n",
    "\n",
    "    calls_since_save = 0\n",
    "    retry = [k for k, v in cache.items() if (v.get('lat') is None or v.get('lon') is None)]\n",
    "    todo = [k for k in unique_place_keys if k and k not in cache] + retry\n",
    "    print(f\"{len(todo)} places to geocode (skipping {len(unique_place_keys) - len(todo)} already cached).\")\n",
    "\n",
    "    for idx, key in enumerate(todo, start=1):\n",
    "        loc = geocode(key)\n",
    "        if loc:\n",
    "            cache[key] = {\n",
    "                \"lat\": loc.latitude,\n",
    "                \"lon\": loc.longitude,\n",
    "                \"display_name\": getattr(loc, \"address\", None),\n",
    "            }\n",
    "            print(f\"[{idx}/{len(todo)}] OK  - {key} -> ({loc.latitude:.6f}, {loc.longitude:.6f})\")\n",
    "        else:\n",
    "            cache[key] = {\"lat\": None, \"lon\": None, \"display_name\": None}\n",
    "            print(f\"[{idx}/{len(todo)}] MISS- {key}\")\n",
    "\n",
    "        calls_since_save += 1\n",
    "        if calls_since_save >= save_every:\n",
    "            save_cache(cache)\n",
    "            print(f\"Saved cache after {calls_since_save} new calls.\")\n",
    "            calls_since_save = 0\n",
    "\n",
    "    save_cache(cache)\n",
    "    print(\"All done. Cache saved to\", str(CACHE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada6bce-d501-4b51-93f1-e069f7869720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unique_place_keys = build_unique_place_keys(primary_df)\n",
    "# geocode_all(unique_place_keys, save_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472eb89-d0d8-423a-bac9-0a42410ba651",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = json.loads(open(\"geocode_cache.json\", encoding=\"utf-8\").read())\n",
    "cache_df = pl.DataFrame({\n",
    "    \"place_key\": list(cache.keys()),\n",
    "    \"lat\": [v[\"lat\"] for v in cache.values()],\n",
    "    \"lon\": [v[\"lon\"] for v in cache.values()],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc5d00-dd00-49dc-882b-55739832c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_locations = primary_df.select(\n",
    "        pl.concat_str(\n",
    "            [pl.col(\"City\"), pl.col(\"State\"), pl.col(\"Country\")],\n",
    "            separator=\", \",\n",
    "            ignore_nulls=True,\n",
    "        ).alias(\"place_key\"))\n",
    "\n",
    "n = 0\n",
    "for p in people_locations['place_key']:\n",
    "    if p in cache_df['place_key'] and not len(cache_df.filter(pl.col('place_key')==p).filter(pl.col('lat').is_null()))>0:\n",
    "        n +=1\n",
    "print(n/len(people_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d4861-3c51-4f3b-9311-f913b812183f",
   "metadata": {},
   "source": [
    "99% of participants' locations returned valid coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686c26c-f98a-4087-bde1-bc0b1bd00063",
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_locations = primary_df.select(\n",
    "        pl.concat_str(\n",
    "            [pl.col(\"Location_City\"), pl.col(\"Location_State\")],\n",
    "            separator=\", \",\n",
    "            ignore_nulls=True,\n",
    "        ).alias(\"place_key\")\n",
    "    ).filter(pl.col('place_key')!=\"\")\n",
    "\n",
    "n2 = 0\n",
    "for m in meeting_locations['place_key']:\n",
    "    if m in cache_df['place_key'] and not len(cache_df.filter(pl.col('place_key')==m).filter(pl.col('lat').is_null()))>0:\n",
    "        n2 +=1\n",
    "print(n2/len(meeting_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5366dc2-dcda-4ba6-b34b-cc2f8015ad7c",
   "metadata": {},
   "source": [
    "100% of meeting locations have coordinates (important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf7e70-76e0-4b80-bceb-d2360981ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_title = [\n",
    "    '2015 CAS Annual Meeting', '2015 CAS Interactive Live Streaming: CLRS', '2015 CAS Spring Meeting',\n",
    "    '2015 CLRS & Workshops', '2015 Ratemaking and Product Management Seminar & Workshops', '2015 Seminar on Reinsurance',\n",
    "    '2016 CAS Annual Meeting', '2016 CAS Interactive Live Streaming: CLRS', '2016 CAS Interactive Live Streaming: Spring',\n",
    "    '2016 CAS Seminar on Reinsurance', '2016 CAS Spring Meeting', '2016 CLRS & Workshops',\n",
    "    '2016 Ratemaking and Product Management Seminar & Workshops', '2017 CAS Annual Meeting',\n",
    "    '2017 CAS Interactive Live Stream: Casualty Loss Reserve Seminar', '2017 CAS Interactive Live Streaming: Annual',\n",
    "    '2017 CAS Interactive Live Streaming: Spring', '2017 CAS Seminar on Reinsurance', '2017 CAS Spring Meeting',\n",
    "    '2017 CLRS & Workshops', '2017 Ratemaking and Product Management Seminar & Workshops', '2018 CAS Annual Meeting',\n",
    "    '2018 CAS Interactive Live Stream: Casualty Loss Reserve Seminar', '2018 CAS Interactive Live Streaming: Annual',\n",
    "    '2018 CAS Interactive Live Streaming: Spring', '2018 CAS Reinsurance Seminar', '2018 CAS Spring Meeting',\n",
    "    '2018 CLRS & Workshops', '2018 RPM Seminar & Workshops', '2019 CAS Annual Meeting',\n",
    "    '2019 CAS Interactive Live Stream: Casualty Loss Reserve Seminar', '2019 CAS Interactive Live Streaming: Annual',\n",
    "    '2019 CAS Interactive Live Streaming: RPM', '2019 CAS Interactive Live Streaming: Reinsurance Seminar',\n",
    "    '2019 CAS Interactive Live Streaming: Spring', '2019 CAS Reinsurance Seminar', '2019 CAS Spring Meeting',\n",
    "    '2019 CLRS & Workshops', '2019 RPM Seminar & Workshops', '2020 Virtual CAS Annual Meeting',\n",
    "    '2020 Virtual CAS Ratemaking, Product, and Modeling Seminar', '2020 Virtual CAS Seminar on Reinsurance',\n",
    "    '2020 Virtual CAS Spring Meeting', '2020 Virtual CLRS', '2021 CAS Annual Meeting',\n",
    "    '2021 CAS Interactive Live Streaming: Annual', '2021 Virtual CAS Ratemaking, Product, and Modeling Seminar',\n",
    "    '2021 Virtual CAS Seminar on Reinsurance', '2021 Virtual CAS Spring Meeting', '2021 Virtual CLRS',\n",
    "    '2022 CAS Annual Meeting', '2022 CAS Interactive Live Streaming: Annual', '2022 CAS Interactive Live Streaming: CLRS',\n",
    "    '2022 CAS Interactive Live Streaming: Spring', '2022 CAS Spring Meeting', '2022 CLRS & Workshops',\n",
    "    '2022 RPM Virtual Seminar', '2022 Virtual CAS Seminar on Reinsurance', '2023 CAS Annual Meeting',\n",
    "    '2023 CAS Interactive Live Streaming: Annual', '2023 CAS Interactive Live Streaming: CLRS',\n",
    "    '2023 CAS Interactive Live Streaming: Spring', '2023 CAS Interactive Livestream RPM',\n",
    "    '2023 CAS Interactive Livestream Reinsurance', '2023 CAS Seminar on Reinsurance', '2023 CAS Spring Meeting',\n",
    "    '2023 CLRS & Workshops', '2023 Ratemaking, Product, and Modeling Seminar', '2024 CAS Annual Meeting',\n",
    "    '2024 CAS Interactive Live Streaming: Annual', '2024 CAS Interactive Live Streaming: CLRS',\n",
    "    '2024 CAS Interactive Live Streaming: Spring', '2024 CAS Interactive Livestream RPM',\n",
    "    '2024 CAS Interactive Livestream Reinsurance', '2024 CAS Ratemaking, Product, and Modeling Seminar',\n",
    "    '2024 CAS Seminar on Reinsurance', '2024 CAS Spring Meeting', '2024 CLRS & Workshops'\n",
    "]\n",
    "\n",
    "event_code = [\n",
    "    '15Annual', '15LIVECLRS', '15Spring', '15CLRS', '2015RPM', '2015REINS', '16Annual', '16LIVECLRS', '16LIVESPR',\n",
    "    '2016REINS', '16Spring', '16CLRS', '2016RPM', '17Annual', '17CLRSLS', '17LIVEANN', 'LIVESPR', '2017REINS',\n",
    "    '17Spring', '17CLRS', '17RPM', '18Annual', '18CLRSLS', '18LIVEANN', 'LIVESPR', '2018REINS', '18Spring', '18CLRS',\n",
    "    '18RPM', '19Annual', '19CLRSLS', '19LIVEANN', '19LIVERPM', 'REILS', 'LIVESPR', '2019REINS', '19Spring', '19CLRS',\n",
    "    '19RPM', '20VirAnn', '20VRPM', '20VREINS', '20VirSprng', '20VRCLRS', '21Annual', '21LiveAnn', '21VRPM',\n",
    "    '21VREINS', '21VirSprng', '21VRCLRS', '22Annual', '22LiveANN', '22LiveCLRS', '22LiveSpr', '22Spring', '22CLRS',\n",
    "    'RPMLive22', '22VREINS', '23Annual', '23Annual Livestream', '23CLRS Livestream', '23LiveSpr', '23LIVERPM',\n",
    "    '23LIVEREI', '23REI', '23Spring', '23CLRS', '23RPM', '24Annual', '24Annual Livestream', '24CLRS Livestream',\n",
    "    '24Spring Livestream', '24RPM Livestream', '24Reins Livestream', '24RPM', '24Reins', '24Spring', '24CLRS'\n",
    "]\n",
    "\n",
    "parent_event = [\n",
    "    '15Annual', '15CLRS', '15Spring', '15CLRS', '2015RPM', '2015REINS', '16Annual', '16CLRS', '16Spring',\n",
    "    '2016REINS', '16Spring', '16CLRS', '2016RPM', '17Annual', '17CLRS', '17Annual', '17Spring', '2017REINS',\n",
    "    '17Spring', '17CLRS', '17RPM', '18Annual', '18CLRS', '18Annual', '18Spring', '2018REINS', '18Spring',\n",
    "    '18CLRS', '18RPM', '19Annual', '19CLRS', '19Annual', '19RPM', '2019REINS', '19Spring', '2019REINS', '19Spring',\n",
    "    '19CLRS', '19RPM', '20VirAnn', '20VRPM', '20VREINS', '20VirSprng', '20VRCLRS', '21Annual', '21Annual',\n",
    "    '21VRPM', '21VREINS', '21VirSprng', '21VRCLRS', '22Annual', '22Annual', '22CLRS', '22Spring', '22Spring',\n",
    "    '22CLRS', 'RPMLive22', '22VREINS', '23Annual', '23Annual', '23CLRS', '23Spring', '23RPM', '23REI', '23REI',\n",
    "    '23Spring', '23CLRS', '23RPM', '24Annual', '24Annual', '24CLRS', '24Spring', '24RPM', '24Reins', '24RPM',\n",
    "    '24Reins', '24Spring', '24CLRS'\n",
    "]\n",
    "\n",
    "parent_event_map = pl.DataFrame({\n",
    "    'Event_Title': event_title,\n",
    "    'Event_Code': event_code,\n",
    "    'parent_event': parent_event\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364cbf90-b6b2-4047-932d-5d19a2974978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = primary_df.with_columns(\n",
    "    home_key = pl.concat_str(\n",
    "        [pl.col(\"City\"), pl.col(\"State\"), pl.col(\"Country\")],\n",
    "        separator=\", \", ignore_nulls=True\n",
    "    ),\n",
    "    meet_key = pl.concat_str(\n",
    "        [pl.col(\"Location_City\"), pl.col(\"Location_State\")],\n",
    "        separator=\", \", ignore_nulls=True\n",
    "    ),\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .join(\n",
    "        cache_df.rename({\"lat\":\"home_lat\",\"lon\":\"home_lon\"}),\n",
    "        left_on=\"home_key\", right_on=\"place_key\", how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        cache_df.rename({\"lat\":\"mtg_lat\",\"lon\":\"mtg_lon\"}),\n",
    "        left_on=\"meet_key\", right_on=\"place_key\", how=\"left\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0fcf0f-4eb9-4665-a777-59eb08296021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "R_KM = 6371.0088\n",
    "MI_PER_KM = 0.621371\n",
    "\n",
    "def haversine_km(s: dict) -> float | None:\n",
    "    lat1, lon1, lat2, lon2 = s[\"home_lat\"], s[\"home_lon\"], s[\"mtg_lat\"], s[\"mtg_lon\"]\n",
    "    if None in (lat1, lon1, lat2, lon2):\n",
    "        return None\n",
    "    φ1, λ1, φ2, λ2 = map(math.radians, (lat1, lon1, lat2, lon2))\n",
    "    dφ = φ2 - φ1\n",
    "    dλ = λ2 - λ1\n",
    "    a = math.sin(dφ/2)**2 + math.cos(φ1)*math.cos(φ2)*math.sin(dλ/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    return R_KM * c\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.struct([\"home_lat\",\"home_lon\",\"mtg_lat\",\"mtg_lon\"])\n",
    "          .map_elements(haversine_km)\n",
    "          .alias(\"distance_km\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        (pl.col(\"distance_km\") * MI_PER_KM).alias(\"distance_mi\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df = df.join(parent_event_map,on=['Event_Title','Event_Code'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2261069-9c9e-496e-af39-605df2d8432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write_csv('primary_data_extra_columns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded655ac-0c52-4e0c-a5cc-6f830320708a",
   "metadata": {},
   "source": [
    "# 3) Supporting Exhibits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561caa91-16e7-4967-a4e7-e6f02ae2e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('primary_data_extra_columns.csv')\n",
    "\n",
    "hybrid_parent_events = df.loc[df['Delivery'] == 'LS', 'parent_event'].unique()\n",
    "\n",
    "df_hybrid = df[df['parent_event'].isin(hybrid_parent_events) & df['Delivery'].isin(['IP', 'LS'])].copy()\n",
    "\n",
    "distance_bins = [0, 50, 200, 500, 1000, 2000, np.inf]\n",
    "bin_labels = [\"0-50\", \"50-200\", \"200-500\", \"500-1000\", \"1000-2000\", \">2000\"]\n",
    "df_hybrid['distance_bin'] = pd.cut(df_hybrid['distance_mi'], bins=distance_bins, labels=bin_labels)\n",
    "\n",
    "grouped = df_hybrid.groupby(['distance_bin', 'membership_type', 'Delivery']).size().unstack('Delivery', fill_value=0)\n",
    "grouped['in_person_rate'] = grouped['IP'] / (grouped['IP'] + grouped['LS'])\n",
    "rate_by_bin = grouped['in_person_rate'].unstack('membership_type')\n",
    "\n",
    "x = np.arange(len(bin_labels))\n",
    "plt.figure(figsize=(6,4))\n",
    "for mtype in ['ACAS', 'FCAS', 'non-member']:\n",
    "    plt.plot(x, rate_by_bin[mtype], marker='o', label=mtype)\n",
    "plt.xticks(x, bin_labels)\n",
    "plt.xlabel('Distance from Event (miles)')\n",
    "plt.ylabel('Percentage Attending In-Person')\n",
    "plt.title('In-Person Attendance Rate by Distance and Membership Status')\n",
    "plt.legend(title='Membership')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee710f-b354-4ac3-84e6-6aaac3eaa06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "attend_counts = df['Customer_ID'].value_counts()\n",
    "\n",
    "one_time_ids = attend_counts[attend_counts == 1].index\n",
    "repeat_ids   = attend_counts[attend_counts > 1].index\n",
    "df['attendee_type'] = np.where(df['Customer_ID'].isin(repeat_ids), 'Repeat', 'One-time')\n",
    "\n",
    "one_time_dists = df[(df['attendee_type']=='One-time') & (~df['distance_mi'].isna())]['distance_mi']\n",
    "repeat_dists   = df[(df['attendee_type']=='Repeat') & (~df['distance_mi'].isna())]['distance_mi']\n",
    "\n",
    "data = [one_time_dists, repeat_dists]\n",
    "labels = ['One-time', 'Repeat']\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.boxplot(data, labels=labels, showmeans=True)\n",
    "plt.ylabel('Distance Traveled to Event (miles)')\n",
    "plt.title('Travel Distance Distribution: One-Time vs Repeat Attendees')\n",
    "\n",
    "for i, group in enumerate(data, start=1):\n",
    "    mean_val = np.mean(group)\n",
    "    median_val = np.median(group)\n",
    "    q25 = np.percentile(group, 25)\n",
    "    q75 = np.percentile(group, 75)\n",
    "    \n",
    "    plt.text(i+0.15, mean_val, f\"Mean: {mean_val:.1f}\", fontsize=8, va=\"center\", color=\"green\")\n",
    "    plt.text(i+0.15, median_val, f\"Median: {median_val:.1f}\", fontsize=8, va=\"center\", color=\"orange\")\n",
    "    plt.text(i+0.15, q25, f\"25%: {q25:.1f}\", fontsize=8, va=\"center\")\n",
    "    plt.text(i+0.15, q75, f\"75%: {q75:.1f}\", fontsize=8, va=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2cfa3-08ce-44d8-ba89-8ed087824990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "events_per_person = df.groupby(\"Customer_ID\")[\"Event_Code\"].nunique()\n",
    "\n",
    "membership_map = df.groupby(\"Customer_ID\")[\"membership_type\"].first()\n",
    "\n",
    "member_flags = (\n",
    "    events_per_person.to_frame(\"events_attended\")\n",
    "    .join(membership_map)\n",
    ")\n",
    "\n",
    "avg_events = member_flags.groupby(\"membership_type\")[\"events_attended\"].mean()\n",
    "\n",
    "categories = [\"ACAS\", \"FCAS\", \"non-member\"]\n",
    "avg_values = [avg_events.get(c, 0) for c in categories]\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.bar(categories, avg_values, color=['#1f77b4','#ff7f0e','#2ca02c'])\n",
    "plt.ylabel('Average Events Attended per Person')\n",
    "plt.title('Engagement by Membership Status')\n",
    "\n",
    "for i, val in enumerate(avg_values):\n",
    "    plt.text(i, val+0.05, f\"{val:.2f}\", ha='center', fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff8ffe-273e-41d0-8827-41842df84970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = df['membership_type'].value_counts()\n",
    "\n",
    "categories = ['ACAS','FCAS','non-member']\n",
    "values = [counts.get(c, 0) for c in categories]\n",
    "\n",
    "colors = ['#1f77b4','#ff7f0e','#2ca02c']\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(\n",
    "    values,\n",
    "    labels=categories,\n",
    "    colors=colors,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    wedgeprops={'edgecolor':'white'}\n",
    ")\n",
    "plt.title('Membership Type Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab097e22-77df-4b60-b94f-7cd01f300a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['is_speaker'] = df['registrant_type_code'].str.contains('Speaker')\n",
    "\n",
    "speaker_pct = df.groupby('membership_type')['is_speaker'].mean() * 100\n",
    "\n",
    "categories = ['ACAS','FCAS','non-member']\n",
    "perc_values = [speaker_pct[c] for c in categories]\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "bars = plt.bar(categories, perc_values, color=['#1f77b4','#ff7f0e','#2ca02c'])\n",
    "plt.ylabel('Percentage of Attendees who are Speakers')\n",
    "plt.title('Speaker vs Non-Speaker Breakdown by Credential Status')\n",
    "\n",
    "for bar, val in zip(bars, perc_values):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2,\n",
    "        val/2,\n",
    "        f\"{val:.1f}%\",\n",
    "        ha='center', va='center',\n",
    "        fontsize=9, fontweight='bold',\n",
    "        color='white'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd58b9d-2b15-45a6-9e2d-5954ec4b0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def categorize_event(code, title):\n",
    "    code = str(code).upper()\n",
    "    title = str(title).upper()\n",
    "    if 'RPM' in code: return 'RPM Seminar'\n",
    "    if 'SPRING' in code or 'SPR' in code: return 'Spring Meeting'\n",
    "    if 'ANNUAL' in code or 'ANN' in code: return 'Annual Meeting'\n",
    "    if 'CLRS' in code: return 'CLRS'\n",
    "    if 'REINS' in code or 'REINSURANCE' in title: return 'Reinsurance Seminar'\n",
    "    return 'Other'\n",
    "df['Event_Series'] = df.apply(lambda row: categorize_event(row['Event_Code'], row['Event_Title']), axis=1)\n",
    "\n",
    "series_nonmem_pct = df.groupby('Event_Series').apply(lambda x: (x['membership_type']=='non-member').mean()*100)\n",
    "\n",
    "main_series = ['RPM Seminar','Spring Meeting','Annual Meeting','CLRS','Reinsurance Seminar']\n",
    "series_nonmem_pct = series_nonmem_pct[series_nonmem_pct.index.isin(main_series)]\n",
    "series_nonmem_pct = series_nonmem_pct.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "bars = plt.bar(series_nonmem_pct.index, series_nonmem_pct.values, color='gray')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('% of Attendees who are CAS Non-Members')\n",
    "plt.title('CAS Non-Member Participation by Event Series')\n",
    "\n",
    "for bar, val in zip(bars, series_nonmem_pct.values):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2,\n",
    "        val/2,\n",
    "        f\"{val:.1f}%\",\n",
    "        ha='center', va='center',\n",
    "        fontsize=9, fontweight='bold',\n",
    "        color='white'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc443c-96fd-4b40-9af6-1fbcc7566bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mode_counts = (\n",
    "    df[df['Delivery'] != 'V']\n",
    "      .groupby('membership_type')['Delivery']\n",
    "      .value_counts(normalize=True)\n",
    "      .unstack(fill_value=0)\n",
    ")\n",
    "mode_counts = mode_counts.reindex(['ACAS','FCAS','non-member'])\n",
    "mode_pct = mode_counts * 100\n",
    "\n",
    "modes = ['IP','LS']\n",
    "colors = ['#1f77b4','#ff7f0e']\n",
    "categories = ['ACAS','FCAS','non-member']\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "bottom = np.zeros(len(categories))\n",
    "\n",
    "for idx, mode in enumerate(modes):\n",
    "    values = mode_pct[mode].values\n",
    "    bars = plt.bar(categories, values, bottom=bottom, color=colors[idx], label=mode)\n",
    "\n",
    "    for bar, val, base in zip(bars, values, bottom):\n",
    "        if val > 0:\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width()/2,\n",
    "                base + val/2,\n",
    "                f\"{val:.1f}%\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                fontsize=8, color=\"white\", fontweight=\"bold\"\n",
    "            )\n",
    "    bottom += values\n",
    "\n",
    "plt.ylabel('Percentage of Attendance Records')\n",
    "plt.title('Attendance Option by Membership Status (In-Person or Live-Stream)')\n",
    "plt.legend(title='Mode', loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820e005-a513-4522-b342-392424f9503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "attend_counts = df['Customer_ID'].value_counts()\n",
    "dist = attend_counts.value_counts().sort_index()\n",
    "\n",
    "max_events = dist.index.max()\n",
    "if max_events > 10:\n",
    "    num_10_plus = dist.loc[10:].sum()\n",
    "    dist = dist.loc[:9]\n",
    "    dist[10] = num_10_plus\n",
    "x_labels = [str(x) if x < 10 else \"10+\" for x in dist.index]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(x_labels, dist.values, color='gray')\n",
    "plt.xlabel('Number of Events Attended')\n",
    "plt.ylabel('Number of Individuals')\n",
    "plt.title('Histogram of Event Attendance Count per Person')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641dc83-e61a-4bda-84ed-3394d7094dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "one_time_count = (attend_counts == 1).sum()\n",
    "repeat_count   = (attend_counts > 1).sum()\n",
    "\n",
    "sizes = [one_time_count, repeat_count]\n",
    "labels = ['One-Time Attendees', 'Repeat Attendees']\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.0f%%', startangle=140, colors=['#8c564b','#9467bd'])\n",
    "plt.title('Overall Attendee Retention')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525480e6-db61-4383-b79d-21f8483b7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Start_Date'] = pd.to_datetime(df['Start_Date'])\n",
    "\n",
    "first_year = df.groupby('Customer_ID')['Start_Date'].min().dt.year\n",
    "years_attended = df.groupby('Customer_ID')['Start_Date'].apply(lambda x: sorted(set(x.dt.year)))\n",
    "\n",
    "cohort_ids = first_year[(first_year == 2017) | (first_year == 2018)].index\n",
    "gaps = []\n",
    "for cid in cohort_ids:\n",
    "    yr_list = years_attended[cid]\n",
    "    if len(yr_list) < 2:\n",
    "        gap = None\n",
    "    else:\n",
    "        gap = yr_list[1] - yr_list[0]\n",
    "    gaps.append(gap if gap is not None else 99)\n",
    "\n",
    "gaps = pd.Series(gaps)\n",
    "cohort_size = len(cohort_ids)\n",
    "years = [0,1,2,3,4,5]\n",
    "return_rates = []\n",
    "for n in years:\n",
    "    if n == 0:\n",
    "        return_rates.append(0.0)\n",
    "    else:\n",
    "        rate = (gaps <= n).mean() * 100\n",
    "        return_rates.append(rate)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(years, return_rates, marker='o')\n",
    "plt.xticks(years)\n",
    "plt.xlabel('Years After Initial Event')\n",
    "plt.ylabel('Percentage of Attendees Returned')\n",
    "plt.title('Cumulative Retention of First-Time Attendee Cohorts (2017 & 2018)')\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "for x, y in zip(years, return_rates):\n",
    "    plt.text(\n",
    "        x, y + 2,\n",
    "        f\"{y:.1f}%\", \n",
    "        ha='center', va='bottom',\n",
    "        fontsize=9, fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6b7b6-3ae9-4856-96cf-4856cf992145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Start_Date'] = pd.to_datetime(df['Start_Date'])\n",
    "first_year = df.groupby('Customer_ID')['Start_Date'].min().dt.year\n",
    "years_attended = df.groupby('Customer_ID')['Start_Date'].apply(lambda x: sorted(set(x.dt.year)))\n",
    "\n",
    "cohort_ids = first_year[(first_year == 2017) | (first_year == 2018)].index\n",
    "gaps = []\n",
    "for cid in cohort_ids:\n",
    "    yr_list = years_attended[cid]\n",
    "    if len(yr_list) < 2:\n",
    "        gap = None\n",
    "    else:\n",
    "        gap = yr_list[1] - yr_list[0]\n",
    "    gaps.append(gap if gap is not None else 99)\n",
    "\n",
    "gaps = pd.Series(gaps)\n",
    "\n",
    "return_dist = gaps[gaps < 99].value_counts().sort_index()\n",
    "return_probs = return_dist / len(gaps) * 100\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "bars = plt.bar(return_probs.index.astype(str), return_probs.values, color='steelblue')\n",
    "plt.xlabel('Years After Initial Event')\n",
    "plt.ylabel('Percent of Cohort Returning in That Year')\n",
    "plt.title('Return Probability by Year (2017–2018 First-Time Attendees)')\n",
    "\n",
    "for bar, val in zip(bars, return_probs.values):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2,\n",
    "        val/2,\n",
    "        f\"{val:.1f}%\",\n",
    "        ha='center', va='center',\n",
    "        color='white', fontsize=9, fontweight='bold'\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0d2cf-5636-4d6c-9f50-7b477711e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "TOP_N = 10\n",
    "\n",
    "df = pd.read_csv('primary_data_extra_columns.csv')\n",
    "\n",
    "members = (\n",
    "    df[df['membership_type'].isin(['ACAS', 'FCAS'])]\n",
    "    .drop_duplicates(subset='Customer_ID')\n",
    ")\n",
    "\n",
    "members_with_coords = members.dropna(subset=['home_lat', 'home_lon'])\n",
    "\n",
    "fig_points = px.scatter_geo(\n",
    "    members_with_coords,\n",
    "    lat='home_lat', lon='home_lon',\n",
    "    scope='usa',\n",
    "    title='CAS Member Locations (ACAS & FCAS)'\n",
    ")\n",
    "fig_points.show()\n",
    "\n",
    "state_counts = (\n",
    "    members_with_coords['State']\n",
    "    .dropna()\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "state_counts.columns = ['State', 'Count']\n",
    "top_states = state_counts.head(TOP_N).sort_values('Count', ascending=True)\n",
    "\n",
    "city_state = (\n",
    "    members_with_coords[['City', 'State']].copy()\n",
    "    .dropna(subset=['City', 'State'])\n",
    ")\n",
    "city_state['City'] = city_state['City'].astype(str).str.strip()\n",
    "city_state['State'] = city_state['State'].astype(str).str.strip()\n",
    "city_state['CityState'] = city_state['City'] + ', ' + city_state['State']\n",
    "\n",
    "city_counts = (\n",
    "    city_state['CityState']\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "city_counts.columns = ['CityState', 'Count']\n",
    "top_cities = city_counts.head(TOP_N).sort_values('Count', ascending=True)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(f\"Top {TOP_N} States by CAS Member Count\",\n",
    "                    f\"Top {TOP_N} Cities by CAS Member Count\")\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=top_states['Count'], y=top_states['State'],\n",
    "        orientation='h',\n",
    "        text=top_states['Count'],\n",
    "        textposition='inside',\n",
    "        insidetextanchor='middle',\n",
    "        textfont=dict(color='white'),\n",
    "        hovertemplate='%{y}: %{x}<extra></extra>'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=top_cities['Count'], y=top_cities['CityState'],\n",
    "        orientation='h',\n",
    "        text=top_cities['Count'],\n",
    "        textposition='inside',\n",
    "        insidetextanchor='middle',\n",
    "        textfont=dict(color='white'),\n",
    "        hovertemplate='%{y}: %{x}<extra></extra>'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    showlegend=False,\n",
    "    margin=dict(l=80, r=40, t=80, b=60)\n",
    ")\n",
    "fig.update_xaxes(title_text='Members', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Members', row=1, col=2)\n",
    "fig.update_yaxes(title_text='', row=1, col=1)\n",
    "fig.update_yaxes(title_text='', row=1, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "## Important Note - These Charts do not print when printed\n",
    "## to PDF, but they are included in the final presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279ea05-0db7-41a6-addb-baf5a0f34930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
